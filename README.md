# Image Captioning with Fine-Tuning and Comparison

This project demonstrates how to fine-tune an image captioning model using the Flickr8k dataset and LoRA (Low-Rank Adaptation) and compare the fine-tuned model's performance with the original pre-trained model.

## Overview

The project is divided into two main parts:
1. Fine-tuning a pre-trained image captioning model on the Flickr8k dataset using LoRA.
2. Comparing the performance of the fine-tuned model with the original pre-trained model on a set of sample images.

## Prerequisites

- Python 3.6+
- PyTorch
- Transformers library from Hugging Face
- Datasets library from Hugging Face
- PEFT (Parameter-Efficient Fine-Tuning) library
- Kaggle API
- pandas
- matplotlib
- PIL (Pillow)
